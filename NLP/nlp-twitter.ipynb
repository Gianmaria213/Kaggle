{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy  as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-12-10T15:37:41.651187Z","iopub.execute_input":"2023-12-10T15:37:41.651572Z","iopub.status.idle":"2023-12-10T15:37:42.167591Z","shell.execute_reply.started":"2023-12-10T15:37:41.651538Z","shell.execute_reply":"2023-12-10T15:37:42.166283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analisi e pulizia dati","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test  = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\ndf_full = pd.concat([df_train, df_test])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:55:14.295693Z","iopub.execute_input":"2023-12-10T16:55:14.296131Z","iopub.status.idle":"2023-12-10T16:55:14.341041Z","shell.execute_reply.started":"2023-12-10T16:55:14.296099Z","shell.execute_reply":"2023-12-10T16:55:14.339359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_full['clean_text'] = df_full.text.replace(regex='(@\\w+)|#|&|!', value='')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:55:56.228256Z","iopub.execute_input":"2023-12-10T16:55:56.228696Z","iopub.status.idle":"2023-12-10T16:55:56.349392Z","shell.execute_reply.started":"2023-12-10T16:55:56.228662Z","shell.execute_reply":"2023-12-10T16:55:56.348081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyspellchecker","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:16:01.182052Z","iopub.execute_input":"2023-12-10T16:16:01.182567Z","iopub.status.idle":"2023-12-10T16:16:15.468054Z","shell.execute_reply.started":"2023-12-10T16:16:01.182525Z","shell.execute_reply":"2023-12-10T16:16:15.466421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:55:57.124511Z","iopub.execute_input":"2023-12-10T16:55:57.125754Z","iopub.status.idle":"2023-12-10T16:55:57.131525Z","shell.execute_reply.started":"2023-12-10T16:55:57.125706Z","shell.execute_reply":"2023-12-10T16:55:57.130314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spellchecker import SpellChecker\n\nspell = SpellChecker()\n\ndef correct_spellings(text):\n    \n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    \n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    \n    return \" \".join([i for i in corrected_text if i != None])\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:55:57.621390Z","iopub.execute_input":"2023-12-10T16:55:57.622157Z","iopub.status.idle":"2023-12-10T16:55:57.714083Z","shell.execute_reply.started":"2023-12-10T16:55:57.622109Z","shell.execute_reply":"2023-12-10T16:55:57.712875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_full['clean_text'] = df_full.clean_text.progress_apply(lambda x: correct_spellings(x))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:55:59.550341Z","iopub.execute_input":"2023-12-10T16:55:59.550782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Word2Vec\n","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nstop=set(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_corpus(df):\n    corpus=[]\n    for tweet in tqdm(df['clean_text']):\n        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n        corpus.append(words)\n    return corpus\n\ncorpus = create_corpus(df_full)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\nw2v = Word2Vec(sentences=corpus, vector_size=50)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:26:10.163547Z","iopub.execute_input":"2023-12-10T18:26:10.163965Z","iopub.status.idle":"2023-12-10T18:26:10.920961Z","shell.execute_reply.started":"2023-12-10T18:26:10.163934Z","shell.execute_reply":"2023-12-10T18:26:10.919682Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"def average_word_vectors(sentence, word_embeddings):\n    vectors = [word_embeddings[word] for word in sentence if word in word_embeddings]\n    if not vectors:\n        return np.zeros(word_embeddings.vector_size)\n    return np.mean(vectors, axis=0)\n\n\ntrain_data = np.array([average_word_vectors(i, w2v.wv) for i in corpus[:len(df_train)]])\ntest_data = np.array([average_word_vectors(i, w2v.wv) for i in corpus[len(df_train):]])\nlabels = df_train.target","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:26:10.923540Z","iopub.execute_input":"2023-12-10T18:26:10.923931Z","iopub.status.idle":"2023-12-10T18:26:11.567744Z","shell.execute_reply.started":"2023-12-10T18:26:10.923897Z","shell.execute_reply":"2023-12-10T18:26:11.566553Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(train_data, labels, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:26:11.569203Z","iopub.execute_input":"2023-12-10T18:26:11.569674Z","iopub.status.idle":"2023-12-10T18:26:11.658620Z","shell.execute_reply.started":"2023-12-10T18:26:11.569631Z","shell.execute_reply":"2023-12-10T18:26:11.657520Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"Accuracy: 0.6730137885751806\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nbase_models = [\n    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n    ('svm', SVC(kernel='linear')),\n]\n\nstacked_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\nstacked_model.fit(X_train, y_train)\n\npredictions = stacked_model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:28:18.622353Z","iopub.execute_input":"2023-12-10T18:28:18.622834Z","iopub.status.idle":"2023-12-10T18:28:18.630226Z","shell.execute_reply.started":"2023-12-10T18:28:18.622797Z","shell.execute_reply":"2023-12-10T18:28:18.628583Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"Accuracy: 0.7255416940249507\n","output_type":"stream"}]},{"cell_type":"code","source":"svm_model = SVC(kernel='linear')\nsvm_model.fit(X_train, y_train)\n\npredictions = svm_model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:26:11.661038Z","iopub.execute_input":"2023-12-10T18:26:11.661791Z","iopub.status.idle":"2023-12-10T18:26:13.724477Z","shell.execute_reply.started":"2023-12-10T18:26:11.661749Z","shell.execute_reply":"2023-12-10T18:26:13.723217Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"Accuracy: 0.6625082074852265\n","output_type":"stream"}]},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\npredictions = rf_model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:26:13.726614Z","iopub.execute_input":"2023-12-10T18:26:13.727009Z","iopub.status.idle":"2023-12-10T18:26:18.220657Z","shell.execute_reply.started":"2023-12-10T18:26:13.726974Z","shell.execute_reply":"2023-12-10T18:26:18.219509Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"Accuracy: 0.7301378857518056\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prova con LSTM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:28:42.866099Z","iopub.execute_input":"2023-12-10T18:28:42.867319Z","iopub.status.idle":"2023-12-10T18:28:57.238767Z","shell.execute_reply.started":"2023-12-10T18:28:42.867264Z","shell.execute_reply":"2023-12-10T18:28:57.237155Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"tweets = df_full.clean_text.values","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:43:09.593752Z","iopub.execute_input":"2023-12-10T18:43:09.594213Z","iopub.status.idle":"2023-12-10T18:43:09.599237Z","shell.execute_reply.started":"2023-12-10T18:43:09.594175Z","shell.execute_reply":"2023-12-10T18:43:09.598276Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  \ntokenizer.fit_on_texts(tweets)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:44:59.029669Z","iopub.execute_input":"2023-12-10T18:44:59.030100Z","iopub.status.idle":"2023-12-10T18:44:59.389806Z","shell.execute_reply.started":"2023-12-10T18:44:59.030068Z","shell.execute_reply":"2023-12-10T18:44:59.388562Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(tweets[:len(df_train)])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:45:12.081138Z","iopub.execute_input":"2023-12-10T18:45:12.082164Z","iopub.status.idle":"2023-12-10T18:45:12.267902Z","shell.execute_reply.started":"2023-12-10T18:45:12.082122Z","shell.execute_reply":"2023-12-10T18:45:12.266674Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"max_sequence_length = 17\npadded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:45:13.333080Z","iopub.execute_input":"2023-12-10T18:45:13.333808Z","iopub.status.idle":"2023-12-10T18:45:13.382402Z","shell.execute_reply.started":"2023-12-10T18:45:13.333762Z","shell.execute_reply":"2023-12-10T18:45:13.381416Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df_train.target, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:45:32.499349Z","iopub.execute_input":"2023-12-10T18:45:32.499794Z","iopub.status.idle":"2023-12-10T18:45:32.508963Z","shell.execute_reply.started":"2023-12-10T18:45:32.499759Z","shell.execute_reply":"2023-12-10T18:45:32.507579Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\nembedding_dim = 50  \n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_sequence_length))\nmodel.add(LSTM(64))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n\naccuracy = model.evaluate(X_test, y_test)[1]\nprint(f\"Test Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T18:49:39.277937Z","iopub.execute_input":"2023-12-10T18:49:39.278370Z","iopub.status.idle":"2023-12-10T18:51:04.331873Z","shell.execute_reply.started":"2023-12-10T18:49:39.278338Z","shell.execute_reply":"2023-12-10T18:51:04.330753Z"},"trusted":true},"execution_count":223,"outputs":[{"name":"stdout","text":"Epoch 1/20\n153/153 [==============================] - 6s 24ms/step - loss: 0.5450 - accuracy: 0.7094 - val_loss: 0.4683 - val_accuracy: 0.7783\nEpoch 2/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.3504 - accuracy: 0.8541 - val_loss: 0.5139 - val_accuracy: 0.7742\nEpoch 3/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.2660 - accuracy: 0.8949 - val_loss: 0.4957 - val_accuracy: 0.7693\nEpoch 4/20\n153/153 [==============================] - 3s 22ms/step - loss: 0.2104 - accuracy: 0.9224 - val_loss: 0.6394 - val_accuracy: 0.7496\nEpoch 5/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.1649 - accuracy: 0.9399 - val_loss: 0.8128 - val_accuracy: 0.7373\nEpoch 6/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.1281 - accuracy: 0.9532 - val_loss: 1.1336 - val_accuracy: 0.7397\nEpoch 7/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.1045 - accuracy: 0.9573 - val_loss: 1.1547 - val_accuracy: 0.7496\nEpoch 8/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.0943 - accuracy: 0.9622 - val_loss: 1.1887 - val_accuracy: 0.7471\nEpoch 9/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.0758 - accuracy: 0.9692 - val_loss: 1.3238 - val_accuracy: 0.7438\nEpoch 10/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.0682 - accuracy: 0.9709 - val_loss: 1.4584 - val_accuracy: 0.7406\nEpoch 11/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.0594 - accuracy: 0.9731 - val_loss: 1.5699 - val_accuracy: 0.7340\nEpoch 12/20\n153/153 [==============================] - 3s 22ms/step - loss: 0.0598 - accuracy: 0.9721 - val_loss: 1.4067 - val_accuracy: 0.7381\nEpoch 13/20\n153/153 [==============================] - 3s 22ms/step - loss: 0.0590 - accuracy: 0.9731 - val_loss: 1.5756 - val_accuracy: 0.7340\nEpoch 14/20\n153/153 [==============================] - 4s 23ms/step - loss: 0.0526 - accuracy: 0.9756 - val_loss: 1.6872 - val_accuracy: 0.7521\nEpoch 15/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.0488 - accuracy: 0.9780 - val_loss: 1.4702 - val_accuracy: 0.7365\nEpoch 16/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.0477 - accuracy: 0.9799 - val_loss: 1.7092 - val_accuracy: 0.7422\nEpoch 17/20\n153/153 [==============================] - 3s 22ms/step - loss: 0.0426 - accuracy: 0.9807 - val_loss: 1.7268 - val_accuracy: 0.7307\nEpoch 18/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.0359 - accuracy: 0.9823 - val_loss: 1.8766 - val_accuracy: 0.7315\nEpoch 19/20\n153/153 [==============================] - 3s 20ms/step - loss: 0.0348 - accuracy: 0.9836 - val_loss: 1.9257 - val_accuracy: 0.7389\nEpoch 20/20\n153/153 [==============================] - 3s 21ms/step - loss: 0.0338 - accuracy: 0.9846 - val_loss: 2.0680 - val_accuracy: 0.7422\n48/48 [==============================] - 0s 5ms/step - loss: 2.0517 - accuracy: 0.7328\nTest Accuracy: 0.7327643036842346\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}